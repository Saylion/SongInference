{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Saylion/SongInference/blob/main/Song_Inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApXHLBri3yZI"
      },
      "source": [
        "<center>\n",
        "<font face=\"verdana\"><font size=\"8\"<strong>SELAMAT DATANG DI SONG INFERENCE COLAB</strong></font>\n",
        "<font face=\"verdana\"><p align=\"center\"><i>Last update at : August 24, 2025</i></p>\n",
        "<img src=\"https://www.gambaranimasi.org/data/media/562/animasi-bergerak-garis-0091.gif\" border=\"0\" height=\"8\" width=\"850\">\n",
        "<br>\n",
        "<a href=\"https://saweria.co/iastudio\"><img alt=\"Saweria\" src=\"https://img.shields.io/badge/Saweria-7B3F00?style=for-the-badge&logo=ko-fi&logoColor=white\"/><a href=\"https://sociabuzz.com/salmizuchannel/tribe\"><img alt=\"Sociabuzz\" src=\"https://img.shields.io/badge/Soziabuzz-%2308d108?style=for-the-badge&logo=kofi&logoColor=white\"/></a><a href=\"https://github.com/Saylion\"><img alt=\"Github\" src=\"https://img.shields.io/badge/github-%23000000?style=for-the-badge&logo=github&logoColor=white\" /></a><a href=\"https://visitorbadge.io/status?path=https%3A%2F%2Fcolab.research.google.com%2Fgithub%2FSaylion%2FSongInverence%2Fblob%2Fmain%2FSong_Inference.ipynb\"><img src=\"https://api.visitorbadge.io/api/visitors?path=https%3A%2F%2Fcolab.research.google.com%2Fgithub%2FSaylion%2FSongInverence%2Fblob%2Fmain%2FSong_Inference.ipynb&countColor=%23263759\" /></a>\n",
        "<br>\n",
        "\n",
        "Jika ada saran atau error, bisa langsung menghubungi email berikut\n",
        "<a href=\"mailto:iacorporation.business@gmail.com\" alt=\"my email\">email me</a>\n",
        "\n",
        "<i>If you have any suggestions or errors,  you can directly contact the following email\n",
        "<a href=\"mailto:iacorporation.business@gmail.com\" alt=\"my email\">email me</a></i>\n",
        "</center>\n",
        "\n",
        "<hr>\n",
        "<br>\n",
        "<p>Changelog (24 Agustus 2025):</p>\n",
        "<ol>\n",
        "  <li>Memperbaiki masalah compatibilitas dependensi<br>\n",
        "    <i>\"Fix dependencies compatibility problem\"</i>\n",
        "  </li><br>\n",
        "</ol>\n",
        "\n",
        "<p>More about <a href=\"https://github.com/Saylion/SongInference/blob/d0c0562fc5b0a3970ba243e0bb4d0119f2d46fe8/changelog.txt\">changelog</a><br></p><br>\n",
        "\n",
        "Google colab collection :\n",
        "<ul>\n",
        "  <li>RVC Mode Training (include inference)</li>\n",
        "\n",
        "<a href=\"https://colab.research.google.com/drive/1-efktIIzxUMu6NqhBX6H57TEseMY3Zee?usp=drive_link\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\"></a>\n",
        "</ul>\n",
        "<br><br><br><br>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run This First\n",
        "\n",
        "!wget -O mini.sh https://repo.anaconda.com/miniconda/Miniconda3-py39_4.9.2-Linux-x86_64.sh\n",
        "!chmod +x mini.sh\n",
        "!bash ./mini.sh -b -f -p /usr/local\n",
        "!conda install -q -y jupyter\n",
        "!conda install -q -y google-colab -c conda-forge\n",
        "!python -m ipykernel install --name \"py39\" --user"
      ],
      "metadata": {
        "id": "Wve8pmaxUdyY",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cVfH-2oSu77d",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Input Form\n",
        "#@markdown Fill modelname to inference <br>\n",
        "#@markdown (bisa multi model, pisahkan dengan spasi atau pilih All model untuk memindahkan semua model dari drive, kosongkan jika ingin menambahkan model nanti)\n",
        "\n",
        "Input_Option = \"Manual\" #@param[\"Manual\", \"All Model\"]\n",
        "\n",
        "Option = Input_Option\n",
        "\n",
        "MODELNAME = \"\"  #@param {type:\"string\", placeholder:\"Masukkan nama model\"}\n",
        "\n",
        "Save_output_song_to_drive = False #@param{type:'boolean'}\n",
        "\n",
        "Save = Save_output_song_to_drive\n",
        "import sys\n",
        "import time\n",
        "!pip install colorama &> /dev/null\n",
        "from tqdm.notebook import tqdm\n",
        "import subprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jHIusMOLwkJI",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Mount/Remount Drive\n",
        "\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "if not os.path.exists('/content/drive'):\n",
        "  drive.mount('/content/drive')\n",
        "else:\n",
        "  drive.flush_and_unmount()\n",
        "  drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h1ysQAC1wp1x",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Clone repository\n",
        "subprocess.Popen(\n",
        "            [\"git\", \"clone\", 'https://github.com/Saylion/SongInference.git'],\n",
        "            stdout=subprocess.PIPE,\n",
        "            stderr=subprocess.PIPE,\n",
        "            text=True,\n",
        "            bufsize=1\n",
        "        )\n",
        "with tqdm(range(100), desc='Clonning Github Repository', bar_format='{l_bar}{bar} |  [{elapsed}]') as pbar:\n",
        "  for i in range(100):\n",
        "    time.sleep(0.05)\n",
        "    pbar.update(1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Fix CUDA Problem\n",
        "from tqdm.notebook import tqdm\n",
        "import time\n",
        "import subprocess\n",
        "\n",
        "\n",
        "with tqdm(range(100), desc='Fixing CUDA Problem', bar_format='{l_bar}{bar} |  [{elapsed}]') as pbar:\n",
        "  pbar.update(10)\n",
        "  time.sleep(0.5)\n",
        "  subprocess.run(f'sudo apt update', shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "  pbar.update(10)\n",
        "  time.sleep(0.5)\n",
        "  subprocess.run('wget https://developer.download.nvidia.com/compute/cudnn/9.3.0/local_installers/cudnn-local-repo-debian12-9.3.0_1.0-1_amd64.deb', shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "  pbar.update(10)\n",
        "  time.sleep(0.5)\n",
        "  subprocess.run('sudo dpkg -i cudnn-local-repo-debian12-9.3.0_1.0-1_amd64.deb', shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "  pbar.update(10)\n",
        "  time.sleep(0.5)\n",
        "  subprocess.run('sudo cp /var/cuda-repo-debian12-9-3-local/cudnn-*-keyring.gpg /usr/share/keyrings/', shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "  pbar.update(10)\n",
        "  time.sleep(0.5)\n",
        "  subprocess.run('sudo add-apt-repository contrib', shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "  pbar.update(10)\n",
        "  time.sleep(0.5)\n",
        "  subprocess.run('sudo apt-get update', shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "  pbar.update(10)\n",
        "  time.sleep(0.5)\n",
        "  subprocess.run('sudo apt-get -y install cudnn-cuda-11', shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "  pbar.update(10)\n",
        "  time.sleep(0.5)\n",
        "  subprocess.run('rm -rf cudnn-local-repo-debian12-9.3.0_1.0-1_amd64.deb ', shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "  pbar.update(10)\n",
        "  subprocess.run(f'rm -rf sample_data', shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "  pbar.update(10)\n",
        "%cd SongInference"
      ],
      "metadata": {
        "id": "T2OVzGRwXoiH",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cjk68x7PwyMq",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Install requirements\n",
        "requirements = open('requirements.txt', 'r').readlines()\n",
        "requirements = [req.strip() for req in requirements]\n",
        "\n",
        "with tqdm(total=len(requirements) + 9, desc='Installing requirements') as pbar:\n",
        "    subprocess.run('pip install pip==24.0', shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "    pbar.update(1)\n",
        "    for req in requirements:\n",
        "        subprocess.run(['pip', 'install', req], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "        pbar.update(1)\n",
        "    subprocess.run('pip install gradio-client==0.16.2', shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "    pbar.update(1)\n",
        "    subprocess.run('pip install gradio==3.48.0', shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "    pbar.update(1)\n",
        "    subprocess.run('pip install torch==2.0.1+cu118 torchaudio==2.0.2+cu118 -f https://download.pytorch.org/whl/torch_stable.html', shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "    pbar.update(1)\n",
        "    subprocess.run('pip install -U demucs', shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "    pbar.update(1)\n",
        "    subprocess.run('sudo apt update', shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "    pbar.update(1)\n",
        "    subprocess.run('sudo apt install sox', shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "    pbar.update(1)\n",
        "    subprocess.run(f'pip install git+https://github.com/One-sixth/fairseq.git', shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "    pbar.update(1)\n",
        "    subprocess.run(f'pip install -U yt-dlp', shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "    pbar.update(1)\n",
        "    pbar.set_description(f'Installing requirements (DONE)')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bLuozp2fw3Np",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Download MDXNet Vocal Separation and Hubert Base Models\n",
        "command = ['python', 'src/download_models.py']\n",
        "\n",
        "\n",
        "\n",
        "with tqdm(total=6, desc='Preparing for download') as pbar:\n",
        "  process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "  stdout, stderr = process.communicate()\n",
        "  output_lines = stdout.decode().splitlines()\n",
        "  for line in output_lines:\n",
        "    if 'UVR-MDX-NET-Voc_FT.onnx' in line:\n",
        "        pbar.set_description(f'Downloading UVR-MDX-NET-Voc_FT.onnx')\n",
        "        time.sleep(1)\n",
        "        pbar.update(1)\n",
        "    if 'UVR_MDXNET_KARA_2.onnx' in line:\n",
        "        pbar.set_description(f'Downloading UVR_MDXNET_KARA_2.onnx')\n",
        "        time.sleep(1)\n",
        "        pbar.update(1)\n",
        "    if 'Reverb_HQ_By_FoxJoy.onnx' in line:\n",
        "        pbar.set_description(f'Downloading Reverb_HQ_By_FoxJoy.onnx.onnx')\n",
        "        time.sleep(1)\n",
        "        pbar.update(1)\n",
        "    if 'hubert_base.pt' in line:\n",
        "        pbar.set_description(f'Downloading hubert_base.pt')\n",
        "        time.sleep(1)\n",
        "        pbar.update(1)\n",
        "    if 'rmvpe.pt' in line:\n",
        "        pbar.set_description(f'Downloading rmvpe.pt')\n",
        "        time.sleep(1)\n",
        "        pbar.update(1)\n",
        "    if 'All models downloaded!' in line:\n",
        "        pbar.set_description(f'All model downloaded')\n",
        "        pbar.update(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJH0VfK6xL6G",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Copy modelname\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "from tqdm.notebook import tqdm\n",
        "import time\n",
        "\n",
        "if MODELNAME == \"\":\n",
        "  print(\"Skipping this section\")\n",
        "\n",
        "else:\n",
        "  path = \"/content/drive/MyDrive/RVC\"\n",
        "\n",
        "  model_input_list = MODELNAME.split(\" \")\n",
        "\n",
        "  folders = os.listdir(path)\n",
        "  array_folders = []\n",
        "  array_final_folders = []\n",
        "  array_model_folders =[]\n",
        "  for folder in folders:\n",
        "    if not os.path.isfile(os.path.join(path, folder)):\n",
        "      array_folders.append(folder)\n",
        "\n",
        "  if Option == \"Manual\":\n",
        "    list_folder = np.array(model_input_list)\n",
        "\n",
        "  if Option == \"All Model\":\n",
        "    list_folder = np.array(array_folders)\n",
        "    index = ['weights', '.ipynb_checkpoints']\n",
        "    list_folder = np.setdiff1d(list_folder, index)\n",
        "\n",
        "  list_folder.sort()\n",
        "\n",
        "  first_list_folder = list_folder\n",
        "\n",
        "  #-------------\n",
        "  #Checking valid model from GDrive\n",
        "\n",
        "  with tqdm(range(10), total=len(list_folder), desc='Checking for valid model   ', unit=' folder', smoothing=0) as pbar:\n",
        "    for folder in list_folder:\n",
        "      if not os.path.exists(os.path.join(path, folder)):\n",
        "        print(f'WARNING : Folder {folder} not found, make sure your input model name is same with your model name folder in GDrive')\n",
        "        continue\n",
        "      list_inModel_folder = np.array(os.listdir(os.path.join(path, folder)))\n",
        "      list_inModel_folder.sort()\n",
        "      weights_path = os.path.join(path, 'weights')\n",
        "      model_weights = f\"{folder}.pth\"\n",
        "      for file in list_inModel_folder:\n",
        "        if file.startswith('added_') and os.path.exists(os.path.join(weights_path, model_weights)):\n",
        "          array_final_folders.append(folder)\n",
        "      time.sleep(0.1)\n",
        "      pbar.update(1)\n",
        "  #-------------\n",
        "\n",
        "  list_final_folder = np.array(array_final_folders)\n",
        "\n",
        "  #-------------\n",
        "  #Copy valid model into RVC model dir\n",
        "\n",
        "  with tqdm(range(10), total=len(list_final_folder), desc='Copying Model            ', unit=' model') as pbar:\n",
        "    for folder in list_final_folder:\n",
        "      pbar.set_description(f'Copying Model ({folder})           ')\n",
        "      !mkdir -p /content/SongInference/rvc_models/{folder}/\n",
        "      !cp /content/drive/MyDrive/RVC/{folder}/added_*.index /content/SongInference/rvc_models/{folder}/ &> /dev/null\n",
        "      !cp -r /content/drive/MyDrive/RVC/weights/{folder}.pth /content/SongInference/rvc_models/{folder} &> /dev/null\n",
        "\n",
        "      #time.sleep(0.1)\n",
        "      pbar.update(1)\n",
        "    pbar.set_description(f'Copying Model (DONE)    ')\n",
        "  #-------------\n",
        "\n",
        "  print('\\nSummary: ')\n",
        "  if len(first_list_folder) != len(list_final_folder):\n",
        "    print('WARNING : There is invalid model appear, make sure your modelname folder have file named added_***_Flat_nprobe_1_modelname.index or weights folder have file modelname.pth')\n",
        "  print(f'\\nThere is {len(list_final_folder)} RVC model exist from {len(list_folder)}\\n')\n",
        "\n",
        "  print('Recent Model List :')\n",
        "  rvc_models_path = '/content/SongInference/rvc_models'\n",
        "  model_folder_list = os.listdir(rvc_models_path)\n",
        "  for folder in model_folder_list:\n",
        "    if not os.path.isfile(os.path.join(rvc_models_path, folder)):\n",
        "      array_model_folders.append(folder)\n",
        "  model_list = np.array(array_model_folders)\n",
        "  model_list.sort()\n",
        "  counter = 1\n",
        "  for model in model_list:\n",
        "    print(f'  {counter}. {model}')\n",
        "    counter += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2U1G-x9_xXJK",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Run WebUI\n",
        "#@markdown Pilih metode tunnel untuk menghasilkan public URL\n",
        "Public_URL = \"Gradio\" #@param[\"Gradio\", \"Localtunnel\", \"Serveo\"]\n",
        "!npm install -g localtunnel &> /dev/null\n",
        "import subprocess\n",
        "import threading\n",
        "import time\n",
        "import socket\n",
        "import urllib.request\n",
        "#from colorama import Fore, Style\n",
        "import os\n",
        "\n",
        "if os.getcwd() != '/content/SongInference':\n",
        "  os.chdir('/content/SongInference')\n",
        "\n",
        "def iframe_thread(port):\n",
        "    while True:\n",
        "        time.sleep(0.5)\n",
        "        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "        result = sock.connect_ex(('127.0.0.1', port))\n",
        "        if result == 0:\n",
        "            break\n",
        "        sock.close()\n",
        "\n",
        "\n",
        "    if Public_URL == \"Localtunnel\":\n",
        "      p = subprocess.Popen([\"lt\", \"--port\", \"{}\".format(port)], stdout=subprocess.PIPE, text=True)\n",
        "    elif Public_URL == \"Serveo\":\n",
        "      p = subprocess.Popen([\"ssh\", \"-q\", \"-o\", \"StrictHostKeyChecking=no\", \"-o\", \"UserKnownHostsFile=/dev/null\", \"-R\", \"80:localhost:{}\".format(port), \"serveo.net\"], stdout=subprocess.PIPE, stderr=subprocess.DEVNULL, text=True)\n",
        "    time.sleep(0.5)\n",
        "    print(\"\\nYour Public URL ---------------------------------------------------------\")\n",
        "    for line in p.stdout:\n",
        "       if Public_URL == \"Localtunnel\":\n",
        "          print(Fore.GREEN + \"\\nLocaltunnel Endpoint IP is:\", Fore.RED, urllib.request.urlopen('https://ipv4.icanhazip.com').read().decode('utf8').strip(\"\\n\"),Style.RESET_ALL)\n",
        "          print(\"\\n\", line.strip())\n",
        "       if Public_URL == \"Serveo\":\n",
        "          if \"Forwarding HTTP traffic from\" in line.strip():\n",
        "           print(\"\\n\", Fore.GREEN + line.strip() + Style.RESET_ALL)\n",
        "       print(\"\\n-------------------------------------------------------------------------\")\n",
        "       break\n",
        "\n",
        "\n",
        "if Public_URL == \"Gradio\":\n",
        "  !python src/webui.py --share\n",
        "else:\n",
        "  threading.Thread(target=iframe_thread, daemon=True, args=(7860,)).start()\n",
        "  if Public_URL == 'All':\n",
        "    !python src/webui.py --share\n",
        "  else:\n",
        "    !python src/webui.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "foMSETJL7f7s",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Copy Output song to drive (Optional)\n",
        "\n",
        "if Save == True:\n",
        "      !mkdir -p /content/drive/MyDrive/Output\n",
        "      !cp -r /content/SongInference/song_output/ /content/drive/MyDrive/Output\n",
        "      print(\"output sudah di copy ke drive\")\n",
        "else:\n",
        "  print(\"output tidak di copy ke drive\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}